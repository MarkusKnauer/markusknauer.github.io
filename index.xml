<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Markus Knauer</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Markus Knauer</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Apr 2025 08:59:00 +0200</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title> *ICRA Paper*: &#34;Grounding Embodied Question-Answering with State Summaries from Existing Robot Modules&#34;  </title>
      <link>http://localhost:1313/posts/icra-rag-embodied-qa/</link>
      <pubDate>Mon, 28 Apr 2025 08:59:00 +0200</pubDate>
      <guid>http://localhost:1313/posts/icra-rag-embodied-qa/</guid>
      <description>&lt;p&gt;Our approach for &lt;strong&gt;truthful&lt;/strong&gt; &lt;strong&gt;foundation model&lt;/strong&gt; (&lt;strong&gt;LLM&lt;/strong&gt;) question-answering using &lt;em&gt;RAG&lt;/em&gt; methods in &lt;strong&gt;robotics&lt;/strong&gt; was accepted by &lt;strong&gt;IEEE ICRA&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/OX-dd5PiiZo?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Paper on IEEE *coming soon!&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://elib.dlr.de/205203/%22&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on Elib&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/OX-dd5PiiZo?si=oB5V8kO_cFpCnSgW&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube Link&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Markus Knauer CV - Robotics &amp; AI Research Experience</title>
      <link>http://localhost:1313/cv/</link>
      <pubDate>Sun, 27 Apr 2025 17:15:34 +0200</pubDate>
      <guid>http://localhost:1313/cv/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://localhost:1313/pdfs/cv_2025_04.pdf&#34; &gt;Download my current CV as PDF&lt;/a&gt;&lt;/p&gt;&#xA;&lt;style&gt;&#xA;.pdf-viewer-large {&#xA;  width: 100%;&#xA;  height: 90vh;&#xA;  min-height: 800px;&#xA;  border: 1px solid #ccc;&#xA;  border-radius: 8px;&#xA;}&#xA;&#xA;@media (max-width: 768px) {&#xA;  .pdf-viewer-large {&#xA;    height: 85vh;&#xA;    min-height: 600px;&#xA;  }&#xA;}&#xA;&#xA;@media (max-width: 480px) {&#xA;  .pdf-viewer-large {&#xA;    height: 80vh;&#xA;    min-height: 500px;&#xA;  }&#xA;}&#xA;&lt;/style&gt;&#xA;&lt;iframe src=&#34;https://mozilla.github.io/pdf.js/web/viewer.html?file=https://markusknauer.github.io/pdfs/cv_2025_04.pdf&#34; class=&#34;pdf-viewer-large&#34; title=&#34;Markus Knauer CV PDF viewer&#34;&gt;&lt;/iframe&gt;</description>
    </item>
    <item>
      <title>About Markus Knauer - Robotics &amp; AI Researcher</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Sun, 27 Apr 2025 17:09:26 +0200</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;picture class=&#34;avatar-image&#34;&gt;&#xA;  &lt;source srcset=&#34;http://localhost:1313/images/avatar.webp&#34; type=&#34;image/webp&#34;&gt;&#xA;  &lt;img src=&#34;http://localhost:1313/images/avatar.jpg&#34; alt=&#34;Markus Knauer - Research Scientist portrait&#34; loading=&#34;lazy&#34;&gt;&#xA;&lt;/picture&gt;&#xA;&lt;p&gt;Hi, I am Markus, a Robot-AI researcher, currently employed by the &lt;a href=&#34;https://rmc.dlr.de/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;German Aerospace Center(DLR)&lt;/a&gt;.&#xA;Right now doing my PhD with the School of Computation, Information and Technology, &lt;a href=&#34;https://www.ce.cit.tum.de/rm/research/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Technical University of Munich (TUM)&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;i class=&#34;fa-solid fa-location-dot&#34;&gt;&lt;/i&gt; Based in Munich, Germany.&lt;/p&gt;&#xA;&lt;p&gt;If you want to reach out, you can find me here:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/MarkusKnauer/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://de.linkedin.com/in/markus-knauer&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Markus-Knauer&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ResearchGate&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bsky.app/profile/markusknauer.bsky.social&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BlueSky&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://twitter.com/KnauerMarkus&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter/X&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.xing.com/profile/Markus_Knauer18/web_profiles&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Xing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Some research related links:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=z2qSMPsAAAAJ&amp;amp;hl=de&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Scholar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://orcid.org/0000-0001-8229-9410&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ORCID&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/author/37089659618&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IEEExplore&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openreview.net/profile?id=~Markus_Knauer1&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenReview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Some work related links:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Academic Publications - Markus Knauer Research Papers</title>
      <link>http://localhost:1313/publications/</link>
      <pubDate>Sun, 27 Apr 2025 17:09:26 +0200</pubDate>
      <guid>http://localhost:1313/publications/</guid>
      <description>&lt;p&gt;Here are my academic publications in the field of robotics, AI, and computer vision, organized by year. Publications where I&amp;rsquo;m first author are highlighted, and recent significant contributions are marked with ðŸš€.&lt;/p&gt;&#xA;&lt;h2 id=&#34;2025&#34;&gt;&#xA;  2025&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#2025&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ðŸš€ &lt;strong&gt;Knauer, M.&lt;/strong&gt;, Albu-SchÃ¤ffer, A., Stulp, F., SilvÃ©rio, J. &amp;ldquo;Interactive incremental learning of generalizable skills with local trajectory modulation&amp;rdquo;, &lt;em&gt;in IEEE Robotics and Automation Letters (&lt;strong&gt;RA-L&lt;/strong&gt;), vol. 10, no. 4, pp. 3398-3405, April 2025 &lt;a href=&#34;https://doi.org/10.1109/LRA.2025.3542209&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1109/LRA.2025.3542209&lt;/a&gt;&lt;/em&gt; ðŸš€&lt;/p&gt;</description>
    </item>
    <item>
      <title> *RA-L Paper*: &#34;Interactive Incremental Learning of Generalizable Skills With Local Trajectory Modulation&#34; </title>
      <link>http://localhost:1313/posts/ral-interactive-incremental-learning/</link>
      <pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/ral-interactive-incremental-learning/</guid>
      <description>&lt;p&gt;Our approach on probabilistic machine learning method for &lt;strong&gt;interactive robot skill modulation&lt;/strong&gt; using a &lt;strong&gt;task-parameterized,&lt;/strong&gt; &lt;strong&gt;kernelized&lt;/strong&gt; method (TP-KMP) got published in IEEE Robotics and Automation Letters (&lt;strong&gt;RA-L&lt;/strong&gt;).&lt;/p&gt;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/nqigz0l1syA?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/10887119/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on IEEE&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2409.05655&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on ArXiv&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://elib.dlr.de/212796/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on Elib&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/nqigz0l1syA&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube Link&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For more information please follow the link to the GitHub project:&lt;/p&gt;</description>
    </item>
    <item>
      <title>*Demonstration*: Showing a task-parameterized approach at Automatica and Hannover fair </title>
      <link>http://localhost:1313/posts/automatica-hannover-demo/</link>
      <pubDate>Mon, 22 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/automatica-hannover-demo/</guid>
      <description>&lt;h1 id=&#34;automatica-2023--hannover-fair-2024&#34;&gt;&#xA;  Automatica 2023 &amp;amp; Hannover fair 2024&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#automatica-2023--hannover-fair-2024&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;picture class=&#34;demo-image&#34;&gt;&#xA;  &lt;source srcset=&#34;http://localhost:1313/images/tradefair.webp&#34; type=&#34;image/webp&#34;&gt;&#xA;  &lt;img src=&#34;http://localhost:1313/images/tradefair.jpeg&#34; alt=&#34;Robotics demonstration at Automatica and Hannover Fair&#34; loading=&#34;lazy&#34;&gt;&#xA;&lt;/picture&gt;&#xA;&lt;p&gt;Presenting a robotic demonstrator at a trade fair is always exciting! ðŸš€&lt;/p&gt;&#xA;&lt;p&gt;At &lt;a href=&#34;https://factory-of-the-future.dlr.de/2023/05/31/27-30-juni-2023-automatica-2023/index.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Automatica 2023&lt;/a&gt; in Munich and &lt;a href=&#34;https://www.dlr.de/de/aktuelles/nachrichten/2024/das-dlr-auf-der-hannover-messe-2024&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hannover fair&lt;/a&gt; 2024 in Hannover I presented an implementation of a Task-Parameterized approach (TP-GMM [1])&#xA;at the booth of the &lt;a href=&#34;https://www.dlr.de/rm&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institute of Robotics and Mechatronics&lt;/a&gt; of the &lt;a href=&#34;https://www.dlr.de&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;German Aerospace Center (DLR)&lt;/a&gt; in the domain of future manufacturing.&#xA;The demonstration showed a ring-measuring task, where the robot arm picks a bearing ring from a box and places it onto a measuring device. Thanks to the task-parameterized approach a generalization to different box and measuring-device positions was possible, which was necessary since we are showing a variable workcell, where changes can and will always happen.&lt;/p&gt;</description>
    </item>
    <item>
      <title> *Project*: BlenderProc: A procedural Blender pipeline for photorealistic rendering. (&gt;3k Stars on GitHub!)</title>
      <link>http://localhost:1313/posts/blenderproc-project/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blenderproc-project/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;&#xA;&lt;img src=&#34;http://localhost:1313/images/blenderproc.gif&#34; alt=&#34;Blenderproc&#34; width=100%&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Very popular &lt;strong&gt;open source&lt;/strong&gt; project for fast creation of training images for &lt;strong&gt;deep neural networks&lt;/strong&gt; in &lt;strong&gt;computer vision&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;For more information please follow the link to the GitHub project:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/DLR-RM/BlenderProc&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/DLR-RM/BlenderProc&lt;/a&gt; (&amp;gt;3k stars)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title> *Published Dataset*: &#34;HOWS-CL-25: Household Objects Within Simulation Dataset for Continual Learning&#34;  </title>
      <link>http://localhost:1313/posts/hows-cl-25-dataset/</link>
      <pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/hows-cl-25-dataset/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt; created with &lt;strong&gt;BlenderProc&lt;/strong&gt;, which includes 150,795 unique synthetic images using 25 different household categories with 925 3D models.&lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;&#xA;  &lt;img src=&#34;http://localhost:1313/images/hows_overview.jpg&#34; width=&#34;500&#34;&gt;&#xA;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://zenodo.org/records/7189434&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link to Dataset&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/9981968&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on IEEE&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.14774&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on ArXiv&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://elib.dlr.de/190097/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on Elib&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/P9buxiinVeI&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube Link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For more information please follow the link to the GitHub project:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/DLR-RM/RECALL&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/DLR-RM/RECALL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>*IROS Paper*: &#34;RECALL: Rehearsal-free Continual Learning for Object Classification&#34; </title>
      <link>http://localhost:1313/posts/recall-continual-learning-iros/</link>
      <pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/recall-continual-learning-iros/</guid>
      <description>&lt;p&gt;Our approach for &lt;strong&gt;rehearsal-free&lt;/strong&gt; &lt;strong&gt;object classification&lt;/strong&gt; in a &lt;strong&gt;continual/incremental&lt;/strong&gt; fashion with &lt;strong&gt;SOTA&lt;/strong&gt; results was published in &lt;strong&gt;IEEE IROS&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/P9buxiinVeI?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/9981968&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on IEEE&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.14774&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on ArXiv&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://elib.dlr.de/190097/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on Elib&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/P9buxiinVeI&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube Link&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For more information please follow the link to the GitHub project:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/DLR-RM/RECALL&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/DLR-RM/RECALL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
