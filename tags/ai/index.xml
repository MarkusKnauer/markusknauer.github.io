<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Markus Knauer</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in AI on Markus Knauer</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>**Automatica 2025:** DLR Showcasing the Future of Robotics</title>
      <link>http://localhost:1313/posts/dlr-automatica-2025/</link>
      <pubDate>Fri, 27 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dlr-automatica-2025/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://automatica-munich.com/en/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Automatica 2025&lt;/a&gt; in Munich showcased the latest advances in robotics and automation technology. DLR made a strong impression with our expansive booth spanning two areas in Hall B4 (Stand 321/324), where we demonstrated cutting-edge robotics and AI integration.&lt;/p&gt;&#xA;&lt;h2 id=&#34;dlrs-robotics-showcase&#34;&gt;&#xA;  DLR&amp;rsquo;s Robotics Showcase&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#dlrs-robotics-showcase&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Our Institute of Robotics and Mechatronics presented five groundbreaking systems:&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.dlr.de/de/rm/forschung/robotersysteme/humanoide/toro&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TORO&lt;/a&gt;&lt;/strong&gt; - Our bipedal humanoid robot demonstrates advanced locomotion, climbing stairs and navigating obstacles with enhanced perception capabilities.&lt;/p&gt;</description>
    </item>
    <item>
      <title>**ICRA 2025:** RACCOON â€” Grounding Embodied Question-Answering in Robotics</title>
      <link>http://localhost:1313/posts/icra-rag-embodied-qa/</link>
      <pubDate>Mon, 28 Apr 2025 08:59:00 +0200</pubDate>
      <guid>http://localhost:1313/posts/icra-rag-embodied-qa/</guid>
      <description>&lt;p&gt;Our approach for &lt;strong&gt;truthful&lt;/strong&gt; &lt;strong&gt;foundation model&lt;/strong&gt; (&lt;strong&gt;LLM&lt;/strong&gt;) question-answering using &lt;em&gt;RAG&lt;/em&gt; methods in &lt;strong&gt;robotics&lt;/strong&gt; was accepted by &lt;strong&gt;IEEE ICRA&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/OX-dd5PiiZo?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/11127843/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on IEEE&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://elib.dlr.de/205203/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on Elib&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/OX-dd5PiiZo?si=oB5V8kO_cFpCnSgW&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube Link&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>**RSS 2024:** Embodied Question-Answering at GenAI-HRI Workshop</title>
      <link>http://localhost:1313/posts/rss-2024-genai-hri-workshop/</link>
      <pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/rss-2024-genai-hri-workshop/</guid>
      <description>&lt;p&gt;We presented our work on &lt;strong&gt;grounded embodied question-answering&lt;/strong&gt; at the &lt;a href=&#34;https://sites.google.com/view/gai-hri-2024&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Generative Modeling meets HRI (GenAI-HRI)&lt;/a&gt; workshop at &lt;a href=&#34;https://roboticsconference.org/2024/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robotics: Science and Systems (RSS) 2024&lt;/a&gt; in Delft, Netherlands.&lt;/p&gt;&#xA;&lt;p&gt;Our approach uses &lt;strong&gt;RAG&lt;/strong&gt; (Retrieval-Augmented Generation) methods to ground &lt;strong&gt;foundation model&lt;/strong&gt; (&lt;strong&gt;LLM&lt;/strong&gt;) responses in actual robot state summaries from existing robot modules, enabling &lt;strong&gt;truthful&lt;/strong&gt; question-answering about the robot&amp;rsquo;s current situation and capabilities.&lt;/p&gt;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/OX-dd5PiiZo?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://elib.dlr.de/205203/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper on Elib&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/OX-dd5PiiZo?si=oB5V8kO_cFpCnSgW&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube Link&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sites.google.com/view/gai-hri-2024&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GenAI-HRI Workshop&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
